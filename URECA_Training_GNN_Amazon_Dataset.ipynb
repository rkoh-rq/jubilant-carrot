{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B8AzmIIcW4K3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import array\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I2EtJIMmH_1_"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "S6Brv28OoTAw"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from scipy.sparse import coo, coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvzgWSpoNhWH"
   },
   "source": [
    "# Data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gctb2druy5pk"
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def readImageFeatures(path):\n",
    "  f = open(path, 'rb')\n",
    "  while True:\n",
    "    asin = f.read(10)\n",
    "    if asin == '': break\n",
    "    a = array.array('f')\n",
    "    try:\n",
    "      a.fromfile(f, 4096)\n",
    "    except:\n",
    "      break\n",
    "    yield asin, a.tolist()\n",
    "\n",
    "def related_convert_to_list(x):\n",
    "  r = set([])\n",
    "  if x.isna()['related']:\n",
    "    return r\n",
    "  else:\n",
    "    x = x['related']\n",
    "    for key in x:\n",
    "      for item in x[key]:\n",
    "        r.add(item)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4AMsi3K0Lli"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHP4YrhRV9Ks"
   },
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "eva6VMBK0MoZ"
   },
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def train_val_test_split(num_total, split_train=0.6, split_val=0.2):\n",
    "  idx_list = [i for i in range(num_total)]\n",
    "  np.random.shuffle(idx_list)\n",
    "\n",
    "  num_train = int(split_train * num_total)\n",
    "  num_val = int((split_train + split_val) * num_total)\n",
    "\n",
    "  idx_train = idx_list[:num_train]\n",
    "  idx_val = idx_list[num_train:num_val]\n",
    "  idx_test = idx_list[num_val:]\n",
    "\n",
    "  return idx_train, idx_val, idx_test\n",
    "\n",
    "def accuracy(output, labels):\n",
    "  correct_false = 0\n",
    "  correct_true = 0\n",
    "  total_false = 0\n",
    "  total_true = 0\n",
    "  for o, l in zip(output, labels):\n",
    "    if l == 0:\n",
    "      total_false += 1\n",
    "      if o == 0:\n",
    "        correct_false += 1\n",
    "    elif l == 1:\n",
    "      total_true += 1\n",
    "      if o == 1:\n",
    "        correct_true += 1\n",
    "  if total_true == 0:\n",
    "    total_true = 1\n",
    "  if total_false == 0:\n",
    "    total_false = 1\n",
    "  return (correct_true + correct_false)/(total_true + total_false), correct_true/total_true, total_true, correct_false/total_false, total_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = 'Musical_Instruments'\n",
    "min_reviews = 3\n",
    "ratings_df = pd.read_csv('ratings_{}.csv'.format(category), header=None)\n",
    "ratings_df = ratings_df[ratings_df.groupby(0)[1].transform('count')>=min_reviews]\n",
    "ratings_df = ratings_df.reset_index(drop=True)\n",
    "movies_ratings_df = pd.read_csv('ratings_Movies_and_TV.csv', header = None)\n",
    "meta_df = getDF('meta_{}.json.gz'.format(category))\n",
    "meta_df = meta_df[['asin', 'related']]\n",
    "meta_df = meta_df.set_index('asin')\n",
    "meta_df = meta_df.apply(lambda x: related_convert_to_list(x), axis=1)\n",
    "\n",
    "image_features_index = {feature[0]:i for i,feature in enumerate(readImageFeatures('image_features_{}.b'.format(category)))}\n",
    "image_features = []\n",
    "for feature in readImageFeatures('image_features_{}.b'.format(category)):\n",
    "    image_features.append(coo_matrix(feature[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SD5SaHiHUDNZ"
   },
   "source": [
    "## Graph (data) loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "bFdY7xfNRlkI"
   },
   "outputs": [],
   "source": [
    "from numpy import zeros, ones\n",
    "from numpy.random import shuffle\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "class GraphLoader():\n",
    "    def __init__(self, category, batch_size=20, min_reviews=3):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "#         ratings_df = pd.read_csv('ratings_{}.csv'.format(category), header=None)\n",
    "#         ratings_df = ratings_df[ratings_df.groupby(0)[1].transform('count')>=min_reviews]\n",
    "#         ratings_df = ratings_df.reset_index(drop=True)\n",
    "\n",
    "        self.ratings_df_reviewer = ratings_df.set_index(0)\n",
    "        self.ratings_df_asin = ratings_df.set_index(1)\n",
    "        self.ratings_df_index = {id:i for i,id in enumerate(self.ratings_df_reviewer.index)}\n",
    "        self.ratings_df_index_i = self.ratings_df_reviewer.index\n",
    "\n",
    "#         movies_ratings_df = pd.read_csv('ratings_Movies_and_TV.csv', header = None)\n",
    "\n",
    "        # Generate labels\n",
    "        self.labels = zeros(len(self.ratings_df_index_i))\n",
    "        for user in self.ratings_df_index_i.intersection(movies_ratings_df[0]):\n",
    "            self.labels[self.ratings_df_index[user]] = 1\n",
    "\n",
    "#         meta_df = getDF('meta_{}.json.gz'.format(category))\n",
    "#         meta_df = meta_df[['asin', 'related']]\n",
    "#         meta_df = meta_df.set_index('asin')\n",
    "#         meta_df = meta_df.apply(lambda x: related_convert_to_list(x), axis=1)\n",
    "        self.meta_df = meta_df\n",
    "        \n",
    "#         self.image_features_index = {feature[0]:i for i,feature in enumerate(readImageFeatures('image_features_{}.b'.format(category)))}\n",
    "#         self.image_features = []\n",
    "#         for feature in readImageFeatures('image_features_{}.b'.format(category)):\n",
    "#             self.image_features.append(coo_matrix(feature[1]))\n",
    "        self.image_features_index = image_features_index\n",
    "        self.image_features = image_features    \n",
    "        \n",
    "        self.idx_train, self.idx_val, self.idx_test = self.train_val_test_split(len(self.ratings_df_index_i))\n",
    "            \n",
    "        self.mode = 'train'\n",
    "        self.idx = self.idx_train\n",
    "\n",
    "    def train_val_test_split(self, num_total, split_train=0.6, split_val=0.2):\n",
    "        idx_list = [i for i in range(num_total)]\n",
    "        shuffle(idx_list)\n",
    "\n",
    "        num_train = int(split_train * num_total)\n",
    "        num_val = int((split_train + split_val) * num_total)\n",
    "\n",
    "        idx_train = idx_list[:num_train]\n",
    "        print(sum(self.labels[idx_train])/len(self.labels[idx_train]))\n",
    "        idx_val = idx_list[num_train:num_val]\n",
    "        print(sum(self.labels[idx_val])/len(self.labels[idx_val]))\n",
    "        idx_test = idx_list[num_val:]\n",
    "        print(sum(self.labels[idx_test])/len(self.labels[idx_test]))\n",
    "\n",
    "        return idx_train, idx_val, idx_test\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.mode == 'train':\n",
    "            shuffle(self.idx_train)\n",
    "            self.idx = self.idx_train\n",
    "        elif self.mode == 'val':\n",
    "            self.idx = self.idx_val\n",
    "        else:\n",
    "            self.idx = self.idx_test\n",
    "        i = 0\n",
    "        for i in range(len(self.idx)):\n",
    "          yield self.get_graph_around_user(self.idx[i])\n",
    "        #     if i % self.batch_size == 0:\n",
    "        #         adj_, feat_, label_ = self.get_graph_around_user(idx[i])\n",
    "        #         adj = adj_.unsqueeze(0)\n",
    "        #         feat = feat_.unsqueeze(0)\n",
    "        #         label = label_.unsqueeze(0)\n",
    "        #     else:\n",
    "        #         adj_, feat_, label_ = self.get_graph_around_user(idx[i])\n",
    "        #         adj = torch.vstack((adj, adj_.unsqueeze(0)))\n",
    "        #         feat = torch.vstack((feat, feat_.unsqueeze(0)))\n",
    "        #         label = torch.vstack((label, label_.unsqueeze(0)))\n",
    "            \n",
    "        #     if i % self.batch_size == self.batch_size - 1:\n",
    "        #         yield adj, feat, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of users\n",
    "        return len(self.idx)\n",
    "\n",
    "    def get_graph_around_user(self, user_idx):\n",
    "        '''\n",
    "        Return a adjacency matrix and feature matrix of graph surrounding the user\n",
    "        '''\n",
    "        user = self.ratings_df_index_i[user_idx]\n",
    "        features = zeros((50, 4096))\n",
    "        G = nx.Graph()\n",
    "        Q = deque()\n",
    "        Q.append((user, 0)) # 0 for user\n",
    "        idx = 0\n",
    "\n",
    "        while Q and G.number_of_nodes() < 50:\n",
    "            node_name, node_type = Q.popleft()\n",
    "            if node_name not in G._node:\n",
    "                if node_type == 1 and bytes(node_name, 'utf-8') in self.image_features_index.keys():\n",
    "                    features[G.number_of_nodes(), :] = self.image_features[self.image_features_index[bytes(node_name, 'utf-8')]].todense()\n",
    "                G.add_node(node_name)\n",
    "\n",
    "            if node_type == 0: # User\n",
    "                products = self.ratings_df_reviewer.loc[node_name][1]\n",
    "                self.add_to_queue_or_graph(Q, G, node_name, products, 1)\n",
    "\n",
    "            else:\n",
    "                if node_name in self.meta_df.index:\n",
    "                    products = self.meta_df.loc[node_name]\n",
    "                    self.add_to_queue_or_graph(Q, G, node_name, products, 1)\n",
    "\n",
    "                if node_name in self.ratings_df_asin.index:\n",
    "                    users = self.ratings_df_asin.loc[node_name][0]\n",
    "                    self.add_to_queue_or_graph(Q, G, node_name, users, 0)\n",
    "\n",
    "        adj = nx.linalg.graphmatrix.adjacency_matrix(G).todense()\n",
    "        adj_pad = np.zeros((50, 50))\n",
    "        adj_pad[:adj.shape[0], :adj.shape[1]] = adj\n",
    "        return torch.Tensor(adj_pad), torch.Tensor(features), torch.LongTensor([self.labels[user_idx]])\n",
    "\n",
    "    def add_to_queue_or_graph(self, Q, G, source, to_add, indicator):\n",
    "        if isinstance(to_add, str):\n",
    "            if to_add not in G._node:\n",
    "                Q.append((to_add, indicator))\n",
    "            else:\n",
    "                G.add_edge(source, to_add)\n",
    "        else:\n",
    "            for t in to_add:\n",
    "                self.add_to_queue_or_graph(Q, G, source, t, indicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "68KTwLXVplRY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07041272228611872\n",
      "0.06509189834782032\n",
      "0.06830999933647403\n"
     ]
    }
   ],
   "source": [
    "graph_loader = GraphLoader('Musical_Instruments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDgAQnY1NBmo"
   },
   "source": [
    "# Train GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6kjm2XfWpMW"
   },
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "xU9lWT7iNEvV"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.matmul(input, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGWThk8jWn7C"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "qV1hbI6XWsIL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nclass, dropout):\n",
    "        \"\"\" 3 layers of GCNs with output dimensions equal to 32, 48, 64 respectively and average all node features \"\"\"\n",
    "        \"\"\" Final classifier with 2 fully connected layers and hidden dimension set to 32 \"\"\"\n",
    "        \"\"\" Activation function - ReLu (Mutag) \"\"\"\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, 1024)\n",
    "        self.gc2 = GraphConvolution(1024, 512)\n",
    "        self.gc3 = GraphConvolution(512, 256)\n",
    "        self.gc4 = GraphConvolution(256, 128)\n",
    "        self.gc5 = GraphConvolution(128, 64)\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, nclass)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc2(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc3(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc4(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu(self.gc5(x, adj))\n",
    "\n",
    "        # prev = 0\n",
    "        # y = []\n",
    "        # for idx in idx_map:\n",
    "        #   y.append(torch.mean(x[prev:idx_map[idx]], 0))\n",
    "        #   prev = idx_map[idx]\n",
    "        # y = torch.stack(y, 0)\n",
    "\n",
    "        # x = x[:num_customers]\n",
    "\n",
    "        # y = []\n",
    "        # for X in x:\n",
    "        #   X = F.relu(self.fc1(X))\n",
    "        #   X = F.dropout(X, self.dropout, training=self.training)\n",
    "        #   X = F.softmax(self.fc2(X), dim=0)\n",
    "        #   y.append(X)\n",
    "        # y = torch.stack(y, 0)\n",
    "\n",
    "        y = x[0]\n",
    "\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = F.dropout(y, self.dropout, training=self.training)\n",
    "        y = F.softmax(self.fc2(y), dim=0)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "GGcJxay4d1WS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "zkRDv8luW1-x"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Parameters\n",
    "\n",
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.epochs = 80\n",
    "args.seed = 100\n",
    "args.cuda = torch.cuda.is_available()\n",
    "args.lr = 0.0001\n",
    "args.dropout = 0.1\n",
    "args.weight_decay = 5e-4\n",
    "args.batch_size = 100\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "model = GCN(nfeat=4096,\n",
    "            nclass=2,\n",
    "            dropout=args.dropout)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "weights = torch.Tensor([1, 16])\n",
    "\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "    weights.cuda()\n",
    "\n",
    "def train(epoch):\n",
    "  t = time.time()\n",
    "  model.train()\n",
    "  optimizer.zero_grad()\n",
    "  graph_loader.mode = 'train'\n",
    "  total_loss_train = 0\n",
    "  output_list = []\n",
    "  labels_list = []\n",
    "\n",
    "  for i, data in enumerate(tqdm(graph_loader, total=len(graph_loader), position=0, leave=True)):\n",
    "      adj, feat, label = data\n",
    "      if args.cuda:\n",
    "          adj = adj.cuda()\n",
    "          feat = feat.cuda()\n",
    "          label = label.cuda()\n",
    "\n",
    "      if i % args.batch_size == 0:\n",
    "          current = model.forward(feat, adj)\n",
    "          output = current.unsqueeze(0)\n",
    "          labels = label\n",
    "      else:\n",
    "          current = model.forward(feat, adj)\n",
    "          output = torch.vstack((output, current.unsqueeze(0)))\n",
    "          labels = torch.vstack((labels, label))\n",
    "\n",
    "      output_list.append(int(torch.argmax(current)))\n",
    "      labels_list.append(int(label))\n",
    "\n",
    "      if i % args.batch_size == args.batch_size - 1:\n",
    "          labels = torch.flatten(labels)\n",
    "          loss_train = F.cross_entropy(\n",
    "              output, labels, weight=weights)\n",
    "          total_loss_train += float(loss_train)\n",
    "          # acc_train = accuracy(output, labels)\n",
    "          loss_train.backward()\n",
    "          optimizer.step()\n",
    "        \n",
    "  f1_train = f1_score(labels_list, output_list)\n",
    "  acc_train = accuracy(output_list, labels_list)\n",
    "  # model.eval()\n",
    "  \n",
    "  print('\\nEpoch: {:04d}'.format(epoch+1),\n",
    "      # 'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "      'total_loss_train: {:.4f}'.format(total_loss_train),\n",
    "      'f1_train: {:.4f}'.format(f1_train),\n",
    "      'acc_train: {:.4f} ({:.4f} of {} true|| {:.4f} of {} false)'.format(acc_train[0], acc_train[1], acc_train[2], acc_train[3], acc_train[4]),\n",
    "      # 'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "      # 'avg_loss_val: {:.4f}'.format(total_loss_val/len(idx_val)),\n",
    "      # 'f1_val: {:.4f}'.format(f1_val),\n",
    "      # 'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "      'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience = 10, min_loss = 0.5, hit_min_before_stopping = False):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.hit_min_before_stopping = hit_min_before_stopping\n",
    "        if hit_min_before_stopping:\n",
    "            self.min_loss = min_loss\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience:\n",
    "              if self.hit_min_before_stopping == True and loss > self.min_loss:\n",
    "                print(\"Cannot hit mean loss, will continue\")\n",
    "                self.counter -= self.patience\n",
    "              else:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CeP7Z5KHuIMg",
    "outputId": "654f6c3e-626d-435c-ba87-2c4b2784cf7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████▊                                                                    | 8198/90424 [15:19<2:00:37, 11.36it/s]"
     ]
    }
   ],
   "source": [
    "for i in range(args.epochs):\n",
    "  train(i)\n",
    "  if i % 5 == 4:\n",
    "    torch.save(model.state_dict(), 'ckpt_{}.pth'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvMNewJm5gfk"
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.module import Module\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU6\n",
    "from torch.nn import Sequential\n",
    "import random\n",
    "\n",
    "import copy\n",
    "\n",
    "MAX_NUM_NODES = 100 # for mutag\n",
    "random.seed(200)\n",
    "\n",
    "class Generator(Module):\n",
    "    def __init__(self, \n",
    "                 C: list,\n",
    "                 c=0,\n",
    "                 hyp1=1, \n",
    "                 hyp2=2, \n",
    "                 start=None,\n",
    "                 nfeat=7,\n",
    "                 dropout=0.1):\n",
    "        \"\"\" \n",
    "        :param C: Candidate set of nodes (list)\n",
    "        :param start: Starting node (defaults to randomised node)\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.nfeat = nfeat\n",
    "        self.dropout = dropout\n",
    "        self.c = c\n",
    "\n",
    "        self.fc = Linear(nfeat, 8)\n",
    "        self.gc1 = GraphConvolution(8, 16)\n",
    "        self.gc2 = GraphConvolution(16, 24)\n",
    "        self.gc3 = GraphConvolution(24, 32)\n",
    "\n",
    "        # MLP1\n",
    "        # 2 FC layers with hidden dimension 16\n",
    "        self.mlp1 = Sequential(Linear(32, 16),\n",
    "                               Linear(16, 1))\n",
    "\n",
    "        # MLP2\n",
    "        # 2 FC layers with hidden dimension 24\n",
    "        self.mlp2 = Sequential(Linear(64, 24),\n",
    "                               Linear(24, 1))\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.hyp1 = hyp1\n",
    "        self.hyp2 = hyp2\n",
    "        self.candidate_set = C\n",
    "        \n",
    "        # Default starting node (if any)\n",
    "        if start is not None:\n",
    "          self.start = start\n",
    "          self.random_start = False\n",
    "        else:\n",
    "          self.start = random.choice(np.arange(0, len(self.candidate_set)))\n",
    "          self.random_start = True\n",
    "\n",
    "        # Load GCN for calculating reward\n",
    "        self.model = GCN(nfeat=features_list[0].shape[1],\n",
    "                         nclass=labels.max().item() + 1,\n",
    "                         dropout=args.dropout)\n",
    "        \n",
    "        self.model.load_state_dict(torch.load(PATH))\n",
    "        for param in self.model.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        self.reset_graph()\n",
    "        \n",
    "    def reset_graph(self):\n",
    "        \"\"\"\n",
    "        Reset g.G to default graph with only start node\n",
    "        \"\"\"\n",
    "        if self.random_start == True:\n",
    "            self.start = random.choice(np.arange(0, len(self.candidate_set)))\n",
    "\n",
    "        mask_start = torch.BoolTensor([False if i == 0 else True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\n",
    "        \n",
    "        adj = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), MAX_NUM_NODES + len(self.candidate_set)), dtype=torch.float32)\n",
    "\n",
    "        feat = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), len(self.candidate_set)), dtype=torch.float32)\n",
    "        feat[0, self.start] = 1\n",
    "        feat[np.arange(-len(self.candidate_set), 0), np.arange(0, len(self.candidate_set))] = 1\n",
    "\n",
    "        degrees = torch.zeros(MAX_NUM_NODES)\n",
    "\n",
    "        self.G = {'adj': adj, 'feat': feat, 'degrees': degrees, 'num_nodes': 1, 'mask_start': mask_start}\n",
    "\n",
    "    def calculate_loss(self, Rt, p_start, a_start, p_end, a_end, G_t_1):\n",
    "        \"\"\"\n",
    "        Calculated from cross entropy loss (Lce) and reward function (Rt)\n",
    "        where loss = -Rt*(Lce_start + Lce_end)\n",
    "        \"\"\"\n",
    "\n",
    "        Lce_start = F.cross_entropy(torch.reshape(p_start, (1, 35)), a_start.unsqueeze(0))\n",
    "        Lce_end = F.cross_entropy(torch.reshape(p_end, (1, 35)), a_end.unsqueeze(0))\n",
    "\n",
    "        return -Rt*(Lce_start + Lce_end)\n",
    "\n",
    "    def calculate_reward(self, G_t_1):\n",
    "        \"\"\"\n",
    "        Rtr     Calculated from graph rules to encourage generated graphs to be valid\n",
    "                1. Only one edge to be added between any two nodes\n",
    "                2. Generated graph cannot contain more nodes than predefined maximum node number\n",
    "                3. (For chemical) Degree cannot exceed valency\n",
    "                If generated graph violates graph rule, Rtr = -1\n",
    "\n",
    "        Rtf     Feedback from trained model\n",
    "        \"\"\"\n",
    "\n",
    "        rtr = self.check_graph_rules(G_t_1)\n",
    "\n",
    "        rtf = self.calculate_reward_feedback(G_t_1)\n",
    "        rtf_sum = 0\n",
    "        for m in range(rollout):\n",
    "            p_start, a_start, p_end, a_end, G_t_1 = self.forward(G_t_1)\n",
    "            rtf_sum += self.calculate_reward_feedback(G_t_1)\n",
    "        rtf = rtf + rtf_sum * self.hyp1 / rollout\n",
    "\n",
    "        return rtf + self.hyp2 * rtr\n",
    "\n",
    "    def calculate_reward_feedback(self, G_t_1):\n",
    "        \"\"\"\n",
    "        p(f(G_t_1) = c) - 1/l\n",
    "        where l denotes number of possible classes for f\n",
    "        \"\"\"\n",
    "        f = self.model(G_t_1['feat'], G_t_1['adj'], None)\n",
    "        return f[self.c] - 1/len(f)\n",
    "\n",
    "    def check_graph_rules(self, G_t_1):\n",
    "        \"\"\"\n",
    "        For mutag, node degrees cannot exceed valency\n",
    "        \"\"\"\n",
    "        idx = 0\n",
    "\n",
    "        for d in G_t_1['degrees']:\n",
    "          if d is not 0:\n",
    "            node_id = torch.argmax(G_t_1['feat'][idx]) # Eg. [0, 1, 0, 0] -> 1\n",
    "            node = self.candidate_set[node_id]  # Eg ['C.4', 'F.2', 'Br.7'][1] = 'F.2'\n",
    "            max_valency = int(node.split('.')[1]) # Eg. C.4 -> ['C', '4'] -> 4\n",
    "\n",
    "            # If any node degree exceeds its valency, return -1\n",
    "            if max_valency < d:\n",
    "                return -1\n",
    "\n",
    "        return 0\n",
    "        \n",
    "    def forward(self, G_in):\n",
    "        G = copy.deepcopy(G_in)\n",
    "\n",
    "        x = G['feat'].detach().clone()\n",
    "        adj = G['adj'].detach().clone()\n",
    "\n",
    "        x = F.relu6(self.fc(x))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu6(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu6(self.gc2(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.relu6(self.gc3(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "        p_start = self.mlp1(x)\n",
    "        p_start = p_start.masked_fill(G['mask_start'].unsqueeze(1), 0)\n",
    "        p_start = F.softmax(p_start, dim=0)\n",
    "        a_start_idx = torch.argmax(p_start.masked_fill(G['mask_start'].unsqueeze(1), -1))\n",
    "        \n",
    "        # broadcast\n",
    "        x1, x2 = torch.broadcast_tensors(x, x[a_start_idx])\n",
    "        x = torch.cat((x1, x2), 1) # cat increases dim from 32 to 64\n",
    "\n",
    "        mask_end = torch.BoolTensor([True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\n",
    "        mask_end[MAX_NUM_NODES:] = False\n",
    "        mask_end[:G['num_nodes']] = False\n",
    "        mask_end[a_start_idx] = True\n",
    "\n",
    "        p_end = self.mlp2(x)\n",
    "        p_end = p_end.masked_fill(mask_end.unsqueeze(1), 0)\n",
    "        p_end = F.softmax(p_end, dim=0)\n",
    "        a_end_idx = torch.argmax(p_end.masked_fill(mask_end.unsqueeze(1), -1))\n",
    "\n",
    "        # Return new G\n",
    "        # If a_end_idx is not masked, node exists in graph, no new node added\n",
    "        if G['mask_start'][a_end_idx] == False:\n",
    "            G['adj'][a_end_idx][a_start_idx] += 1\n",
    "            G['adj'][a_start_idx][a_end_idx] += 1\n",
    "            \n",
    "            # Update degrees\n",
    "            G['degrees'][a_start_idx] += 1\n",
    "            G['degrees'][G['num_nodes']] += 1\n",
    "        else:\n",
    "            # Add node\n",
    "            G['feat'][G['num_nodes']] = G['feat'][a_end_idx]\n",
    "            # Add edge\n",
    "            G['adj'][G['num_nodes']][a_start_idx] += 1\n",
    "            G['adj'][a_start_idx][G['num_nodes']] += 1\n",
    "            # Update degrees\n",
    "            G['degrees'][a_start_idx] += 1\n",
    "            G['degrees'][G['num_nodes']] += 1\n",
    "\n",
    "            # Update start mask\n",
    "            G_mask_start_copy = G['mask_start'].detach().clone()\n",
    "            G_mask_start_copy[G['num_nodes']] = False\n",
    "            G['mask_start'] = G_mask_start_copy\n",
    "            \n",
    "            G['num_nodes'] += 1\n",
    "\n",
    "        return p_start, a_start_idx, p_end, a_end_idx, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zYJUqcgIzv0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "URECA Training GNN - Amazon Dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
